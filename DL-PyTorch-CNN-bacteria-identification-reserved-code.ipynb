{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "#for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import copy\n",
    "# set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: load train data for input\n",
    "# X = train_waveforms\n",
    "# train_waveforms = np.load('data/wavenumbers.npy')      #(1000)       #y()\n",
    "train_waveforms = np.load('data/X_reference.npy')      #(60000,1000) #y(60000)\n",
    "# train_waveforms = np.load('data/X_2018clinical.npy')   #(10000,1000) #y(10000)\n",
    "# train_waveforms = np.load('data/X_2019clinical.npy')   #(2500, 1000) #y(2500)\n",
    "# train_waveforms = np.load('data/X_finetune.npy')       #(3000, 1000) #y(1000)\n",
    "train_waveforms_pd = pd.DataFrame(train_waveforms)\n",
    "\n",
    "# step 2: convert into tensor\n",
    "train_waveforms = torch.tensor(train_waveforms).float()\n",
    "\n",
    "# test_waveforms\n",
    "# step 1 dash: load test data\n",
    "test_waveforms = np.load('data/X_test.npy')           #(3000, 1000) #y(3000)\n",
    "\n",
    "# step 2 dash: convert into tensor\n",
    "test_waveforms = torch.tensor(test_waveforms).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: load train data for output\n",
    "# y = train_labels\n",
    "train_labels = np.load('data/y_reference.npy')      #(60000,1000) #y(60000)\n",
    "# train_labels = np.load('data/y_2018clinical.npy')   #(10000,1000) #y(10000)\n",
    "# train_labels = np.load('data/y_2019clinical.npy')   #(2500, 1000) #y(2500)\n",
    "# train_labels = np.load('data/y_finetune.npy')       #(3000, 1000) #y(1000)\n",
    "# train_labels = np.load('data/y_test.npy')           #(3000, 1000) #y(3000)\n",
    "train_labels_pd = pd.DataFrame(train_labels)\n",
    "\n",
    "# step 2: convert into tensor\n",
    "train_labels = torch.tensor(train_labels).float()\n",
    "train_labels = train_labels[:,None]\n",
    "\n",
    "# test_waveforms\n",
    "# step 1 dash: load test data\n",
    "test_labels = np.load('data/y_test.npy')           #(3000, 1000) #y(3000)\n",
    "\n",
    "# step 2 dash: convert into tensor\n",
    "test_labels = torch.tensor(test_labels).float()\n",
    "test_labels = test_labels[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1000])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_waveforms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 1000])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_waveforms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: convert into tensor dataset\n",
    "train_dataset = TensorDataset(train_waveforms, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: convert into tensor dataset\n",
    "test_dataset = TensorDataset(test_waveforms, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Translate into dataloader objects\n",
    "batchsize    = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batchsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_waveforms_pd.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Deep Learning Model\n",
    "def createTheNet(printtoggle=False):\n",
    "    class cnnClassNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.print = printtoggle\n",
    "            \n",
    "            imgSize = (train_waveforms_pd.shape[1]) #1000\n",
    "            # print('imgsize= ',imgSize)\n",
    "            inChans  = 1 # RGB\n",
    "            outChans = 16 # feature maps # of kernels\n",
    "            krnSize  = 3 # odd number\n",
    "            padding  = 2 # square if single input\n",
    "            stride   = 2 # use maxpool instead of stride ... so stride = 1\n",
    "            \n",
    "            ###########################################\n",
    "            ###########################################\n",
    "            # First Convolution Layer\n",
    "            #Conv2d(in_channels # of channels,\n",
    "            #       out_channels # feature maps kernels, \n",
    "            #       kernel_size, \n",
    "            #       stride,\n",
    "            #       padding  )\n",
    "            self.conv1  = nn.Conv1d(inChans,outChans,krnSize, stride, padding)\n",
    "            self.bnorm1 = nn.BatchNorm1d(outChans) # 64\n",
    "            outputSize = np.floor( (imgSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "            # output size = floor( (1000 + 2*2 - 3) / 2 ) + 1 = 501\n",
    "            \n",
    "            # padding\n",
    "            padding = 1\n",
    "            \n",
    "            # Second Convolution Layer\n",
    "            self.conv2  = nn.Conv1d(outChans,outChans*2,krnSize, stride, padding)\n",
    "            self.bnorm2 = nn.BatchNorm1d(outChans*2) # 128\n",
    "            outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (501 + 2*0 - 3) / 2 ) + 1 = 250\n",
    "            self.conv_residual1 = nn.Conv1d(inChans, outChans*2, kernel_size=1, stride=4,padding=1)  # For residual connection\n",
    "            # output size = floor( (1000 + 2*1 - 1) / 4 ) + 1 = 250\n",
    "            \n",
    "            ###########################################\n",
    "            ###########################################\n",
    "\n",
    "            \n",
    "            # Third Convolution Layer\n",
    "            self.conv3  = nn.Conv1d(outChans*2,outChans*4,krnSize, stride, padding)\n",
    "            self.bnorm3 = nn.BatchNorm1d(outChans*4) # 256\n",
    "            outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (250 + 2*0 - 3) / 2 ) + 1 = 124\n",
    "\n",
    "            # fourth Convolution Layer\n",
    "            self.conv4  = nn.Conv1d(outChans*4,outChans*8,krnSize, stride, padding)\n",
    "            self.bnorm4 = nn.BatchNorm1d(outChans*2*2*2) # 512\n",
    "            outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (124 + 2*1 - 3) / 2 ) + 1 = 63\n",
    "            self.conv_residual2  = nn.Conv1d(outChans*2,outChans*8,kernel_size=1, stride=4, padding=0)\n",
    "            # output size = floor( (250 + 2*0 - 1) / 4 ) + 1 = 63\n",
    "\n",
    "            ###########################################\n",
    "            ###########################################\n",
    "\n",
    "            # fifth Convolution Layer\n",
    "            self.conv5  = nn.Conv1d(outChans*8,outChans*16,krnSize, stride, padding)\n",
    "            self.bnorm5 = nn.BatchNorm1d(outChans*2*2*2*2) # 1024\n",
    "            outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (6 + 2*1 - 3) / 2 ) + 1 = 32\n",
    "            \n",
    "            # Sixth Convolution Layer\n",
    "            self.conv6  = nn.Conv1d(outChans*16,outChans*32,krnSize, stride, padding)\n",
    "            self.bnorm6 = nn.BatchNorm1d(outChans*32) # 2048\n",
    "            outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (63 + 2*1 - 3) / 2 ) + 1 = 16\n",
    "            self.conv_residual3  = nn.Conv1d(outChans*8,outChans*32,kernel_size=1, stride=4, padding=0)\n",
    "            # output size = floor( (63 + 2*0 - 1) / 4 ) + 1 = 16\n",
    "\n",
    "            ###########################################\n",
    "            ###########################################\n",
    "\n",
    "            # seventh Convolution Layer\n",
    "            # self.conv7  = nn.Conv1d(outChans*2*2*2*2*2,outChans*2*2*2*2*2*2,krnSize, stride, padding)\n",
    "            # self.bnorm7 = nn.BatchNorm1d(outChans*2*2*2*2*2) # 4096\n",
    "            # outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (16 + 2*2 - 3) / 2 ) + 1 = 8\n",
    "\n",
    "            # eight Convolution Layer\n",
    "            # self.conv8  = nn.Conv1d(outChans*2,outChans*2*2,krnSize, stride, padding)\n",
    "            # self.bnorm8 = nn.BatchNorm2d(outChans*2*2) # 256\n",
    "            # outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (6 + 2*2 - 3) / 2 ) + 1 = 2\n",
    "            \n",
    "            # ninth Convolution Layer\n",
    "            # self.conv9  = nn.Conv1d(outChans*2,outChans*2*2,krnSize, stride, padding)\n",
    "            # self.bnorm9 = nn.BatchNorm2d(outChans*2*2) # 256\n",
    "            # outputSize = np.floor( (outputSize+2*padding-krnSize)/stride ) + 1\n",
    "            # output size = floor( (4 + 2*2 - 3) / 2 ) + 1 = 1\n",
    "\n",
    "            ### ------- Linear Layer ------- ###\n",
    "            # self.fc1 = nn.Linear(flattened_size,200) #1024, 256\n",
    "            # flattened_size = (outputSize**2) * (outChans*2*2)\n",
    "            #output size**2 = w * h  &&& outchan of last conv layer = 6 * 4096 = 24576\n",
    "            # flattened_size = (outputSize**2) * (outChans*32) \n",
    "            self.flat_features = self.get_flat_features(imgSize)\n",
    "            # print(flattened_size)\n",
    "            # self.fc1 = nn.Linear(int(flattened_size),5000) #24576, 5000\n",
    "            self.fc1 = nn.Linear(self.flat_features,1000) #24576, 5000\n",
    "            self.fc2 = nn.Linear(1000,1)\n",
    "            \n",
    "        def get_flat_features(self, imgSize):\n",
    "            # Helper function to calculate the size of the flattened output\n",
    "            x = torch.randn(1, 1, imgSize)\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.conv4(x)\n",
    "            x = self.conv5(x)\n",
    "            x = self.conv6(x)\n",
    "            return x.numel()\n",
    "\n",
    "        def forward(self, x):\n",
    "            \n",
    "            #############################\n",
    "            x_resid = x\n",
    "            if self.print: print(f'Input: {list(x.shape)}')\n",
    "            if self.print: print(f'Input residual: {list(x_resid.shape)}')\n",
    "            \n",
    "            #first conv -> maxpool -> batchnorm -> relu\n",
    "            #CPBR block\n",
    "            x = self.conv1(x)\n",
    "            x = self.bnorm1(x)\n",
    "            x = F.relu( x  )\n",
    "            if self.print: print(f'First conv: {list(x.shape)}')\n",
    "            \n",
    "            x = self.conv2(x)\n",
    "            if self.print: print(f'Second conv: {list(x.shape)}')\n",
    "            x_resid = self.conv_residual1(x_resid)\n",
    "            if self.print: print(f'1st block residual: {list(x_resid.shape)}')\n",
    "            x = self.bnorm2(x) + x_resid\n",
    "            x = F.relu( x  )\n",
    "            #############################\n",
    "            # print(\"####################################\")\n",
    "            x_resid = x\n",
    "            if self.print: print(f'2nd input residual: {list(x_resid.shape)}')\n",
    "            x = self.conv3(x) \n",
    "            if self.print: print(f'Third conv: {list(x.shape)}')\n",
    "            x = self.bnorm3(x) \n",
    "            x = F.relu( x )\n",
    "\n",
    "            x = self.conv4(x) \n",
    "            if self.print: print(f'Fourth conv: {list(x.shape)}')\n",
    "            x_resid = self.conv_residual2(x_resid)\n",
    "            if self.print: print(f'2nd block residual: {list(x_resid.shape)}')\n",
    "            x = self.bnorm4(x) + x_resid\n",
    "            x = F.relu( x )\n",
    "            #############################\n",
    "            # print(\"####################################\")\n",
    "            x_resid = x\n",
    "            if self.print: print(f'3rd input residual: {list(x_resid.shape)}')\n",
    "            x = self.conv5(x)\n",
    "            if self.print: print(f'Fifth conv: {list(x.shape)}')\n",
    "            x = self.bnorm5(x)\n",
    "            x = F.relu( x )\n",
    "\n",
    "            x = self.conv6(x)\n",
    "            if self.print: print(f'Sixth conv: {list(x.shape)}')\n",
    "            x_resid = self.conv_residual3(x_resid)\n",
    "            if self.print: print(f'3rd block residual: {list(x_resid.shape)}')\n",
    "            x = self.bnorm6(x) + x_resid\n",
    "            x = F.relu( x )\n",
    "            #############################\n",
    "            # print(\"####################################\")\n",
    "\n",
    "            # x = self.conv7(x)\n",
    "            # if self.print: print(f'Seventh conv: {list(x.shape)}')\n",
    "            # x = F.relu( self.bnorm7(x)  )\n",
    "\n",
    "            #reshape for linear layer\n",
    "            nUnits = x.shape.numel()/x.shape[0]\n",
    "            x = x.view(-1, int(nUnits))\n",
    "            if self.print: print(f'Vectorized: {list(x.shape)}')\n",
    "            \n",
    "            # Linear layers\n",
    "            x = F.relu( self.fc1(x)   )\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "            if self.print: print(f'fc1: {list(x.shape)}')\n",
    "                        \n",
    "            x = self.fc2(x)\n",
    "            if self.print: print(f'Final Output: {list(x.shape)}')\n",
    "            \n",
    "            \n",
    "            return x\n",
    "        \n",
    "    modelInstance = cnnClassNet().to(device)\n",
    "    \n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(modelInstance.parameters(), lr=0.001)\n",
    "                                #weight_decay=1e-4)#, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    return modelInstance, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Test with 1 batch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m net2, lossfun2, optimizer2 \u001b[38;5;241m=\u001b[39m \u001b[43mcreateTheNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# X, y = next(iter(train_loader))\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n",
      "Cell \u001b[1;32mIn[131], line 193\u001b[0m, in \u001b[0;36mcreateTheNet\u001b[1;34m(printtoggle)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m--> 193\u001b[0m modelInstance \u001b[38;5;241m=\u001b[39m \u001b[43mcnnClassNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m lossfun \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m    197\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(modelInstance\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test with 1 batch\n",
    "net2, lossfun2, optimizer2 = createTheNet(True)\n",
    "\n",
    "# X, y = next(iter(train_loader))\n",
    "for X, y in train_loader:\n",
    "\n",
    "    print(X.shape)\n",
    "    X = X.unsqueeze(1)  # Add channel dimension\n",
    "    print(X.shape)\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    yHat = net2(X)\n",
    "\n",
    "    #check size of output\n",
    "    print(yHat.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    #compute the loss\n",
    "    loss = lossfun2(yHat, y)\n",
    "    print(loss)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "def trainTheModel(trainedModel, lossfun, optimizer, epochs=1000):\n",
    "    \n",
    "    #number of epochs to train\n",
    "    numepochs = epochs\n",
    "    trainedModel.train()\n",
    "        \n",
    "    #initialize losses & accuracy\n",
    "    trainLoss   = torch.zeros(numepochs)\n",
    "    trainAcc = []\n",
    "    testLoss   = torch.zeros(numepochs)\n",
    "    testAcc  = []\n",
    "\n",
    "    for epochi in range(numepochs):\n",
    "        \n",
    "        #batch loss & accuracy\n",
    "        trainBatchLoss = []\n",
    "        trainBatchAcc  = []\n",
    "        \n",
    "        #loop over mini-batches\n",
    "        for X,y in train_loader:\n",
    "            \n",
    "            # push data to GPU\n",
    "            X = X.unsqueeze(1)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #Forward pass & loss\n",
    "            yHat = trainedModel(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "            \n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #loss from this batch\n",
    "            trainBatchLoss.append(loss.item())\n",
    "            \n",
    "            #accuracy from this batch -> for BCE sigmoid\n",
    "            # trainMatches = torch.sigmoid(yHat) > 0.9 ##\n",
    "            # trainMatchesNumeric = trainMatches.float()\n",
    "            # trainBatchAcc.append( torch.mean( (trainMatchesNumeric == y.float()).float() ).item() )\n",
    "\n",
    "            # batchMathces = (torch.abs(yHat - y)).detach().cpu().float().numpy()\n",
    "            # batchAcc.append(( batchMathces < 0.5))\n",
    "            \n",
    "            # accuracy from this batch for categorical data cross entropy loss\n",
    "            accMatches = torch.argmax(yHat, axis=1)\n",
    "            accMatchesNumeric = (accMatches == y).float()\n",
    "            trainBatchAcc.append( torch.mean(accMatchesNumeric).item() )\n",
    "        \n",
    "        #average accuracy across mini-batches\n",
    "        trainAcc.append(100 * np.mean((trainBatchAcc)))\n",
    "        \n",
    "        #average losses across all mini-batches\n",
    "        trainLoss[epochi] = np.mean(trainBatchLoss)\n",
    "        \n",
    "        ################################\n",
    "        # eval mode\n",
    "        # do not use dropout \n",
    "        # do not use batch normalization instead use avg\n",
    "        trainedModel.eval()\n",
    "\n",
    "        #batch loss & accuracy\n",
    "        testBatchLoss = []\n",
    "        testBatchAcc  = []\n",
    "        #final forward pass for Test Accuracy\n",
    "        # X,y = next(iter(dev_loader))\n",
    "        for X, y in test_loader:\n",
    "            \n",
    "            # push data to GPU\n",
    "            X = X.unsqueeze(1).to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            #forward pass & loss\n",
    "            with torch.no_grad():\n",
    "                yHat = trainedModel(X)\n",
    "                loss = lossfun(yHat, y)\n",
    "            \n",
    "            #batch loss    \n",
    "            testBatchLoss.append(loss.item())\n",
    "            \n",
    "            #batch acc cross entropy\n",
    "            accMatches = torch.argmax(yHat, axis=1)\n",
    "            accMatchesNumeric = (accMatches == y).float()\n",
    "            testAcc.append( torch.mean(accMatchesNumeric).item() )\n",
    "\n",
    "            # batch acc bce\n",
    "            # testMatches = torch.sigmoid(yHat) > 0.9\n",
    "            # testMatchesNumeric = testMatches.float()\n",
    "            # testAcc.append(100 * torch.mean( (testMatchesNumeric == y.float()).float() ).item() )\n",
    "\n",
    "\n",
    "        #compute the test accuracy for categorical data\n",
    "        testLoss[epochi] = ( np.mean(testBatchLoss) )\n",
    "        \n",
    "        testAcc.append(100*np.mean(testBatchAcc))\n",
    "\n",
    "        # testMatches = (torch.abs(yHat - y)).detach().cpu().float().numpy()\n",
    "        # testMatchesNumeric = (testMatches < 1)\n",
    "        # testAcc.append(100 * np.mean( testMatchesNumeric ) )\n",
    "\n",
    "        #compute the test accuracy for BCE sigmoid\n",
    "        \n",
    "        # Acc for categorization\n",
    "        # accMatches = torch.argmax(yHat, axis=1)\n",
    "        # accMatchesNumeric = (accMatches == y).float()\n",
    "        # testBatchAcc.append( torch.mean(accMatchesNumeric).item() )\n",
    "\n",
    "    # return losses, trainedModel\n",
    "    # return trainAcc, losses, trainedModel\n",
    "    return trainAcc, trainLoss, testAcc, testLoss, trainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the training code that it has NO ERRORS\n",
    "# epochs=1\n",
    "# myModelInstance2, lossfun2, optimizer2 = createTheNet()\n",
    "# # losses2, trainedModel2 = trainTheModel(myModelInstance2, lossfun, optimizer, epochs)\n",
    "# # trainAcc2, losses2, trainedModel2 = trainTheModel(myModelInstance2, lossfun, optimizer, epochs)\n",
    "# trainAcc2, trainLoss2, testAcc2, testLoss2, trainedModel2 = trainTheModel(myModelInstance2, lossfun2, optimizer2, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "epochs=2\n",
    "myModelInstance, lossfun, optimizer = createTheNet()\n",
    "trainAcc, trainLoss, testAcc, testLoss, trainedModel = trainTheModel(myModelInstance, lossfun, optimizer, epochs)\n",
    "# trainAcc, losses, trainedModel = trainTheModel(myModelInstance, lossfun, optimizer)\n",
    "# trainAcc, testAcc, losses, trainedModel = trainTheModel(myModelInstance, lossfun, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(trainLoss, label='Train')\n",
    "# ax[0].plot(testLoss, label='Dev')\n",
    "# ax[0].legend()\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model Loss')\n",
    "ax[0].set_xlim([0,5])\n",
    "\n",
    "ax[1].plot(trainAcc, label='Train')\n",
    "ax[1].plot(testAcc, label='Test')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_title(f'Train accuracy {trainAcc[-1]:.2f}%')\n",
    "ax[1].set_ylim([0,110])\n",
    "ax[1].set_xlim([0,5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria_dict = { \n",
    "     0 :\"MRSA 1\"\n",
    "    ,1 :\"MRSA 2\"\n",
    "    ,2 :\"MSSA 1\"\n",
    "    ,3 :\"MSSA 2\"\n",
    "    ,4 :\"MSSA 3\"\n",
    "    ,5 :\"S. epidermidis\"\n",
    "    ,6 :\"S. lugdunensis\"\n",
    "    ,7 :\"S. pneumoniae 1\"\n",
    "    ,8 :\"S. pneumoniae 2\"\n",
    "    ,9 :\"Group A Strep.\"\n",
    "    ,10:\"Group B Strep.\"\n",
    "    ,11:\"Group C Strep.\"\n",
    "    ,12:\"Group G Strep.\"\n",
    "    ,13:\"S. sanguinis\"\n",
    "    ,14:\"E. faecalis 1\"\n",
    "    ,15:\"E. faecalis 2\"\n",
    "    ,16:\"E. faecium\"\n",
    "    ,17:\"E. coli 1\"\n",
    "    ,18:\"E. coli 2\"\n",
    "    ,19:\"K. pneumoniae 1\"\n",
    "    ,20:\"K. pneumoniae 2\"\n",
    "    ,21:\"K. aerogenes\"\n",
    "    ,22:\"E. cloacae\"\n",
    "    ,23:\"P. mirabilis\"\n",
    "    ,24:\"S. marcescens\"\n",
    "    ,25:\"S. enterica\"\n",
    "    ,26:\"P. aeruginosa 1\"\n",
    "    ,27:\"P. aeruginosa 2\"\n",
    "    ,28:\"C. albicans\"\n",
    "    ,29:\"C. glabrata\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test clinic train loader with trained model ... \n",
    "### to know which out is which! reverse engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loader => 2018 clinical dataset\n",
    "X_ref = np.load('data/X_2018clinical.npy')       #(10000,1000) #y(10000)\n",
    "train_waveforms = X_ref.reshape(X_ref.shape[0], 1, X_ref.shape[1])\n",
    "train_waveforms = torch.tensor(train_waveforms).float()\n",
    "train_labels = np.load('data/y_2018clinical.npy')       #(10000,1000) #y(10000)\n",
    "test_labels = np.load('data/y_test.npy')           #(3000, 1000) #y(3000)\n",
    "train_labels = torch.tensor(train_labels).long()\n",
    "train_dataset = TensorDataset(train_waveforms, train_labels)\n",
    "batchsize    = 20\n",
    "batchsize    = len(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "\n",
    "for X, y in train_loader:\n",
    "\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    trainedModel.eval()\n",
    "    \n",
    "    yHat = trainedModel(X)\n",
    "    \n",
    "\n",
    "# print(f'y    shape = {y.shape}')\n",
    "# print(f'yHat shape = {yHat_labels.shape}')\n",
    "\n",
    "# sns.set_context(\"talk\", rc={\"font\":\"Helvetica\", \"font.size\":12})\n",
    "\n",
    "# label = [antibiotics[i] for i in {0,1,2,3,4,5,6}]\n",
    "\n",
    "\n",
    "# cm = confusion_matrix(y, yHat_labels, labels=ab_order)\n",
    "# cm = 100 * cm / cm.sum(axis=1)[:,np.newaxis]\n",
    "\n",
    "# plt.figure(figsize=(5, 4))\n",
    "# ax = sns.heatmap(cm, annot=True, cmap='YlGnBu', fmt='1.0f',\n",
    "#                  xticklabels={0,1,2,3,4,5,6}, yticklabels={0,1,2,3,4,5,6})\n",
    "# ax.xaxis.tick_top()\n",
    "# plt.xticks(rotation=90) \n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loader => 2018 clinical dataset\n",
    "X_ref = np.load('data/X_2019clinical.npy')       #(10000,1000) #y(10000)\n",
    "train_waveforms = X_ref.reshape(X_ref.shape[0], 1, X_ref.shape[1])\n",
    "train_waveforms = torch.tensor(train_waveforms).float()\n",
    "train_labels = np.load('data/y_2019clinical.npy')       #(10000,1000) #y(10000)\n",
    "train_labels = torch.tensor(train_labels).long()\n",
    "train_dataset = TensorDataset(train_waveforms, train_labels)\n",
    "batchsize    = 20\n",
    "batchsize    = len(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "\n",
    "for X, y in train_loader:\n",
    "\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    trainedModel.eval()\n",
    "    \n",
    "    yHat = trainedModel(X)\n",
    "    \n",
    "y       = y.detach().cpu().numpy()\n",
    "yHat    = yHat.detach().cpu().numpy()\n",
    "yHat_labels = np.argmax(yHat, axis=1)\n",
    "\n",
    "y00,y01,y02,y03,y04,y05,y06,y07 = 0,0,0,0,0,0,0,0\n",
    "y10,y11,y12,y13,y14,y15,y16,y17 = 0,0,0,0,0,0,0,0\n",
    "y20,y21,y22,y23,y24,y25,y26,y27 = 0,0,0,0,0,0,0,0\n",
    "y30,y31,y32,y33,y34,y35,y36,y37 = 0,0,0,0,0,0,0,0\n",
    "y40,y41,y42,y43,y44,y45,y46,y47 = 0,0,0,0,0,0,0,0\n",
    "y50,y51,y52,y53,y54,y55,y56,y57 = 0,0,0,0,0,0,0,0\n",
    "y60,y61,y62,y63,y64,y65,y66,y67 = 0,0,0,0,0,0,0,0\n",
    "occurrence_matrix = np.zeros((7, 8))\n",
    "\n",
    "for m, n in zip(y, yHat_labels):\n",
    "\n",
    "    # Add conditions for each combination of m and n\n",
    "    if m == 0 and n == 0:\n",
    "        y00 += 1\n",
    "    elif m == 0 and n == 1:\n",
    "        y01 += 1\n",
    "    elif m == 0 and n == 2:\n",
    "        y02 += 1\n",
    "    elif m == 0 and n == 3:\n",
    "        y03 += 1\n",
    "    elif m == 0 and n == 4:\n",
    "        y04 += 1\n",
    "    elif m == 0 and n == 5:\n",
    "        y05 += 1\n",
    "    elif m == 0 and n == 6:\n",
    "        y06 += 1\n",
    "    elif m == 0 and n == 7:\n",
    "        y07 += 1\n",
    "\n",
    "    elif m == 1 and n == 0:\n",
    "        y10 += 1\n",
    "    elif m == 1 and n == 1:\n",
    "        y11 += 1\n",
    "    elif m == 1 and n == 2:\n",
    "        y12 += 1\n",
    "    elif m == 1 and n == 3:\n",
    "        y13 += 1\n",
    "    elif m == 1 and n == 4:\n",
    "        y14 += 1\n",
    "    elif m == 1 and n == 5:\n",
    "        y15 += 1\n",
    "    elif m == 1 and n == 6:\n",
    "        y16 += 1\n",
    "    elif m == 1 and n == 7:\n",
    "        y17 += 1\n",
    "\n",
    "    elif m == 2 and n == 0:\n",
    "        y20 += 1\n",
    "    elif m == 2 and n == 1:\n",
    "        y21 += 1\n",
    "    elif m == 2 and n == 2:\n",
    "        y22 += 1\n",
    "    elif m == 2 and n == 3:\n",
    "        y23 += 1\n",
    "    elif m == 2 and n == 4:\n",
    "        y24 += 1\n",
    "    elif m == 2 and n == 5:\n",
    "        y25 += 1\n",
    "    elif m == 2 and n == 6:\n",
    "        y26 += 1\n",
    "    elif m == 2 and n == 7:\n",
    "        y27 += 1\n",
    "\n",
    "    elif m == 3 and n == 0:\n",
    "        y30 += 1\n",
    "    elif m == 3 and n == 1:\n",
    "        y31 += 1\n",
    "    elif m == 3 and n == 2:\n",
    "        y32 += 1\n",
    "    elif m == 3 and n == 3:\n",
    "        y33 += 1\n",
    "    elif m == 3 and n == 4:\n",
    "        y34 += 1\n",
    "    elif m == 3 and n == 5:\n",
    "        y35 += 1\n",
    "    elif m == 3 and n == 6:\n",
    "        y36 += 1\n",
    "    elif m == 3 and n == 7:\n",
    "        y37 += 1\n",
    "\n",
    "    elif m == 4 and n == 0:\n",
    "        y40 += 1\n",
    "    elif m == 4 and n == 1:\n",
    "        y41 += 1\n",
    "    elif m == 4 and n == 2:\n",
    "        y42 += 1\n",
    "    elif m == 4 and n == 3:\n",
    "        y43 += 1\n",
    "    elif m == 4 and n == 4:\n",
    "        y44 += 1\n",
    "    elif m == 4 and n == 5:\n",
    "        y45 += 1\n",
    "    elif m == 4 and n == 6:\n",
    "        y46 += 1\n",
    "    elif m == 4 and n == 7:\n",
    "        y47 += 1\n",
    "\n",
    "    elif m == 5 and n == 0:\n",
    "        y50 += 1\n",
    "    elif m == 5 and n == 1:\n",
    "        y51 += 1\n",
    "    elif m == 5 and n == 2:\n",
    "        y52 += 1\n",
    "    elif m == 5 and n == 3:\n",
    "        y53 += 1\n",
    "    elif m == 5 and n == 4:\n",
    "        y54 += 1\n",
    "    elif m == 5 and n == 5:\n",
    "        y55 += 1\n",
    "    elif m == 5 and n == 6:\n",
    "        y56 += 1\n",
    "    elif m == 5 and n == 7:\n",
    "        y57 += 1\n",
    "\n",
    "    elif m == 6 and n == 0:\n",
    "        y60 += 1\n",
    "    elif m == 6 and n == 1:\n",
    "        y61 += 1\n",
    "    elif m == 6 and n == 2:\n",
    "        y62 += 1\n",
    "    elif m == 6 and n == 3:\n",
    "        y63 += 1\n",
    "    elif m == 6 and n == 4:\n",
    "        y64 += 1\n",
    "    elif m == 6 and n == 5:\n",
    "        y65 += 1\n",
    "    elif m == 6 and n == 6:\n",
    "        y66 += 1\n",
    "    elif m == 6 and n == 7:\n",
    "        y67 += 1\n",
    "        \n",
    "print(f'y    = {y}')\n",
    "print(f'yHat = {yHat_labels}')\n",
    "\n",
    "# Print the final counts\n",
    "print(f'y00: {y00}, y01: {y01}, y02: {y02}, y03: {y03}, y04: {y04}, y05: {y05}, y06: {y06}, y07: {y07}')\n",
    "print(f'y10: {y10}, y11: {y11}, y12: {y12}, y13: {y13}, y14: {y14}, y15: {y15}, y16: {y16}, y17: {y17}')\n",
    "print(f'y20: {y20}, y21: {y21}, y22: {y22}, y23: {y23}, y24: {y24}, y25: {y25}, y26: {y26}, y27: {y27}')\n",
    "print(f'y30: {y30}, y31: {y31}, y32: {y32}, y33: {y33}, y34: {y34}, y35: {y35}, y36: {y36}, y37: {y37}')\n",
    "print(f'y40: {y40}, y41: {y41}, y42: {y42}, y43: {y43}, y44: {y44}, y45: {y45}, y46: {y46}, y47: {y47}')\n",
    "print(f'y50: {y50}, y51: {y51}, y52: {y52}, y53: {y53}, y54: {y54}, y55: {y55}, y56: {y56}, y57: {y57}')\n",
    "print(f'y60: {y60}, y61: {y61}, y62: {y62}, y63: {y63}, y64: {y64}, y65: {y65}, y66: {y66}, y67: {y67}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
